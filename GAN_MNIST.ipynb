{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 하나의 블록(block) 정의\n",
    "        def block(input_dim, output_dim, normalize=True):\n",
    "            layers = [nn.Linear(input_dim, output_dim)]\n",
    "            if normalize:\n",
    "                # 배치 정규화(batch normalization) 수행(차원 동일)\n",
    "                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        # 생성자 모델은 연속적인 여러 개의 블록을 가짐\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, 1 * 28 * 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자(Discriminator) 클래스 정의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 * 28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1)\n",
    "        output = self.model(flattened)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터셋 불러오기\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./dataset', train=True, download=True, transform=transforms_train)\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 샘플링\n",
    "# 학습을 위해 생성자와 판별자모델 초기화\n",
    "# 적절한 하이퍼 파라미터 설정\n",
    "\n",
    "# initialize Generator & Discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "adversarial_loss.to(device)\n",
    "\n",
    "# Learning Rate\n",
    "lr = 0.0002\n",
    "\n",
    "# Optimizer for G & D\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss: 0.619810] [G loss: 1.989339] [Elapsed time: 10.64s]\n",
      "[Epoch 1/200] [D loss: 0.260693] [G loss: 1.173720] [Elapsed time: 20.55s]\n",
      "[Epoch 2/200] [D loss: 0.300729] [G loss: 1.171016] [Elapsed time: 29.22s]\n",
      "[Epoch 3/200] [D loss: 0.557267] [G loss: 0.548077] [Elapsed time: 37.47s]\n",
      "[Epoch 4/200] [D loss: 0.723447] [G loss: 0.301939] [Elapsed time: 46.07s]\n",
      "[Epoch 5/200] [D loss: 0.272771] [G loss: 1.395925] [Elapsed time: 58.14s]\n",
      "[Epoch 6/200] [D loss: 0.360840] [G loss: 0.936666] [Elapsed time: 71.91s]\n",
      "[Epoch 7/200] [D loss: 0.319158] [G loss: 3.385357] [Elapsed time: 84.44s]\n",
      "[Epoch 8/200] [D loss: 0.210386] [G loss: 2.618644] [Elapsed time: 94.53s]\n",
      "[Epoch 9/200] [D loss: 0.233650] [G loss: 2.961058] [Elapsed time: 105.21s]\n",
      "[Epoch 10/200] [D loss: 0.207324] [G loss: 2.164872] [Elapsed time: 114.20s]\n",
      "[Epoch 11/200] [D loss: 0.613283] [G loss: 0.480463] [Elapsed time: 124.18s]\n",
      "[Epoch 12/200] [D loss: 0.282079] [G loss: 4.196071] [Elapsed time: 134.41s]\n",
      "[Epoch 13/200] [D loss: 0.225128] [G loss: 2.436913] [Elapsed time: 144.07s]\n",
      "[Epoch 14/200] [D loss: 0.476487] [G loss: 1.145209] [Elapsed time: 154.24s]\n",
      "[Epoch 15/200] [D loss: 0.180758] [G loss: 1.997739] [Elapsed time: 166.73s]\n",
      "[Epoch 16/200] [D loss: 0.358747] [G loss: 0.925970] [Elapsed time: 178.37s]\n",
      "[Epoch 17/200] [D loss: 0.210162] [G loss: 1.424232] [Elapsed time: 190.40s]\n",
      "[Epoch 18/200] [D loss: 0.232018] [G loss: 1.676005] [Elapsed time: 201.87s]\n",
      "[Epoch 19/200] [D loss: 0.160256] [G loss: 1.710596] [Elapsed time: 216.33s]\n",
      "[Epoch 20/200] [D loss: 0.130805] [G loss: 2.104785] [Elapsed time: 225.33s]\n",
      "[Epoch 21/200] [D loss: 0.126016] [G loss: 4.661177] [Elapsed time: 234.19s]\n",
      "[Epoch 22/200] [D loss: 0.191637] [G loss: 1.758744] [Elapsed time: 245.92s]\n",
      "[Epoch 23/200] [D loss: 0.099712] [G loss: 2.807537] [Elapsed time: 255.86s]\n",
      "[Epoch 24/200] [D loss: 0.148167] [G loss: 2.156180] [Elapsed time: 266.69s]\n",
      "[Epoch 25/200] [D loss: 0.187743] [G loss: 2.269940] [Elapsed time: 281.36s]\n",
      "[Epoch 26/200] [D loss: 0.198685] [G loss: 1.345199] [Elapsed time: 292.99s]\n",
      "[Epoch 27/200] [D loss: 0.179140] [G loss: 1.908201] [Elapsed time: 303.30s]\n",
      "[Epoch 28/200] [D loss: 0.144714] [G loss: 2.479571] [Elapsed time: 313.23s]\n",
      "[Epoch 29/200] [D loss: 0.194183] [G loss: 2.406049] [Elapsed time: 323.37s]\n",
      "[Epoch 30/200] [D loss: 0.115344] [G loss: 2.423718] [Elapsed time: 333.80s]\n",
      "[Epoch 31/200] [D loss: 0.192864] [G loss: 1.720339] [Elapsed time: 343.99s]\n",
      "[Epoch 32/200] [D loss: 0.084954] [G loss: 2.972172] [Elapsed time: 356.95s]\n",
      "[Epoch 33/200] [D loss: 0.113218] [G loss: 3.298075] [Elapsed time: 366.59s]\n",
      "[Epoch 34/200] [D loss: 0.124489] [G loss: 2.412006] [Elapsed time: 377.06s]\n",
      "[Epoch 35/200] [D loss: 0.215646] [G loss: 1.680177] [Elapsed time: 386.66s]\n",
      "[Epoch 36/200] [D loss: 0.092798] [G loss: 2.869537] [Elapsed time: 396.64s]\n",
      "[Epoch 37/200] [D loss: 0.153587] [G loss: 3.182539] [Elapsed time: 405.89s]\n",
      "[Epoch 38/200] [D loss: 0.150104] [G loss: 2.270885] [Elapsed time: 415.65s]\n",
      "[Epoch 39/200] [D loss: 0.096484] [G loss: 3.149143] [Elapsed time: 424.61s]\n",
      "[Epoch 40/200] [D loss: 0.171557] [G loss: 3.184876] [Elapsed time: 434.25s]\n",
      "[Epoch 41/200] [D loss: 0.205728] [G loss: 4.982085] [Elapsed time: 442.39s]\n",
      "[Epoch 42/200] [D loss: 0.141399] [G loss: 2.429271] [Elapsed time: 450.55s]\n",
      "[Epoch 43/200] [D loss: 0.194108] [G loss: 4.696817] [Elapsed time: 458.65s]\n",
      "[Epoch 44/200] [D loss: 0.480661] [G loss: 2.346771] [Elapsed time: 466.65s]\n",
      "[Epoch 45/200] [D loss: 0.266887] [G loss: 1.709281] [Elapsed time: 474.69s]\n",
      "[Epoch 46/200] [D loss: 0.316135] [G loss: 4.824888] [Elapsed time: 482.67s]\n",
      "[Epoch 47/200] [D loss: 0.459182] [G loss: 5.722435] [Elapsed time: 490.78s]\n",
      "[Epoch 48/200] [D loss: 0.148016] [G loss: 1.806898] [Elapsed time: 498.72s]\n",
      "[Epoch 49/200] [D loss: 0.085189] [G loss: 2.992361] [Elapsed time: 506.69s]\n",
      "[Epoch 50/200] [D loss: 0.101553] [G loss: 2.692371] [Elapsed time: 514.61s]\n",
      "[Epoch 51/200] [D loss: 0.150421] [G loss: 3.092464] [Elapsed time: 522.61s]\n",
      "[Epoch 52/200] [D loss: 0.194016] [G loss: 4.915899] [Elapsed time: 530.57s]\n",
      "[Epoch 53/200] [D loss: 0.173578] [G loss: 7.697900] [Elapsed time: 538.78s]\n",
      "[Epoch 54/200] [D loss: 0.113293] [G loss: 2.896957] [Elapsed time: 546.72s]\n",
      "[Epoch 55/200] [D loss: 0.228586] [G loss: 3.331989] [Elapsed time: 555.03s]\n",
      "[Epoch 56/200] [D loss: 0.211406] [G loss: 2.163949] [Elapsed time: 563.45s]\n",
      "[Epoch 57/200] [D loss: 0.122662] [G loss: 3.398579] [Elapsed time: 571.45s]\n",
      "[Epoch 58/200] [D loss: 0.103857] [G loss: 2.573551] [Elapsed time: 579.60s]\n",
      "[Epoch 59/200] [D loss: 0.154929] [G loss: 3.228789] [Elapsed time: 587.44s]\n",
      "[Epoch 60/200] [D loss: 0.161018] [G loss: 2.318616] [Elapsed time: 595.56s]\n",
      "[Epoch 61/200] [D loss: 0.065161] [G loss: 3.575874] [Elapsed time: 603.43s]\n",
      "[Epoch 62/200] [D loss: 0.131221] [G loss: 3.157530] [Elapsed time: 611.55s]\n",
      "[Epoch 63/200] [D loss: 0.176517] [G loss: 2.251372] [Elapsed time: 619.93s]\n",
      "[Epoch 64/200] [D loss: 0.173216] [G loss: 4.173701] [Elapsed time: 628.07s]\n",
      "[Epoch 65/200] [D loss: 0.185663] [G loss: 1.810307] [Elapsed time: 635.95s]\n",
      "[Epoch 66/200] [D loss: 0.122778] [G loss: 2.327363] [Elapsed time: 644.05s]\n",
      "[Epoch 67/200] [D loss: 0.176013] [G loss: 1.798791] [Elapsed time: 651.94s]\n",
      "[Epoch 68/200] [D loss: 0.156768] [G loss: 2.923383] [Elapsed time: 660.06s]\n",
      "[Epoch 69/200] [D loss: 0.144433] [G loss: 2.462041] [Elapsed time: 668.03s]\n",
      "[Epoch 70/200] [D loss: 0.240794] [G loss: 1.657744] [Elapsed time: 676.40s]\n",
      "[Epoch 71/200] [D loss: 0.150476] [G loss: 2.227117] [Elapsed time: 684.50s]\n",
      "[Epoch 72/200] [D loss: 0.200952] [G loss: 2.689739] [Elapsed time: 692.55s]\n",
      "[Epoch 73/200] [D loss: 0.145295] [G loss: 4.458219] [Elapsed time: 700.45s]\n",
      "[Epoch 74/200] [D loss: 0.222905] [G loss: 2.072915] [Elapsed time: 708.91s]\n",
      "[Epoch 75/200] [D loss: 0.127275] [G loss: 4.348402] [Elapsed time: 719.14s]\n",
      "[Epoch 76/200] [D loss: 0.098239] [G loss: 3.238369] [Elapsed time: 729.27s]\n",
      "[Epoch 77/200] [D loss: 0.126179] [G loss: 2.098092] [Elapsed time: 737.44s]\n",
      "[Epoch 78/200] [D loss: 0.334001] [G loss: 2.466720] [Elapsed time: 746.43s]\n",
      "[Epoch 79/200] [D loss: 0.204718] [G loss: 1.875568] [Elapsed time: 756.01s]\n",
      "[Epoch 80/200] [D loss: 0.136704] [G loss: 2.460566] [Elapsed time: 766.07s]\n",
      "[Epoch 81/200] [D loss: 0.132204] [G loss: 2.847897] [Elapsed time: 775.33s]\n",
      "[Epoch 82/200] [D loss: 0.111321] [G loss: 3.466304] [Elapsed time: 784.05s]\n",
      "[Epoch 83/200] [D loss: 0.123181] [G loss: 3.957472] [Elapsed time: 792.75s]\n",
      "[Epoch 84/200] [D loss: 0.136893] [G loss: 2.996291] [Elapsed time: 802.36s]\n",
      "[Epoch 85/200] [D loss: 0.193328] [G loss: 3.165536] [Elapsed time: 811.89s]\n",
      "[Epoch 86/200] [D loss: 0.122330] [G loss: 2.323694] [Elapsed time: 823.53s]\n",
      "[Epoch 87/200] [D loss: 0.174353] [G loss: 3.960441] [Elapsed time: 832.33s]\n",
      "[Epoch 88/200] [D loss: 0.166539] [G loss: 1.743425] [Elapsed time: 841.89s]\n",
      "[Epoch 89/200] [D loss: 0.155027] [G loss: 3.074950] [Elapsed time: 850.69s]\n",
      "[Epoch 90/200] [D loss: 0.179116] [G loss: 3.274412] [Elapsed time: 859.65s]\n",
      "[Epoch 91/200] [D loss: 0.086268] [G loss: 3.039106] [Elapsed time: 868.63s]\n",
      "[Epoch 92/200] [D loss: 0.136819] [G loss: 2.646909] [Elapsed time: 877.97s]\n",
      "[Epoch 93/200] [D loss: 0.186046] [G loss: 3.285301] [Elapsed time: 888.05s]\n",
      "[Epoch 94/200] [D loss: 0.071380] [G loss: 3.159525] [Elapsed time: 897.13s]\n",
      "[Epoch 95/200] [D loss: 0.151198] [G loss: 3.299297] [Elapsed time: 908.06s]\n",
      "[Epoch 96/200] [D loss: 0.072735] [G loss: 3.165537] [Elapsed time: 919.51s]\n",
      "[Epoch 97/200] [D loss: 0.137191] [G loss: 3.643525] [Elapsed time: 929.29s]\n",
      "[Epoch 98/200] [D loss: 0.145235] [G loss: 2.672058] [Elapsed time: 939.45s]\n",
      "[Epoch 99/200] [D loss: 0.117735] [G loss: 4.115996] [Elapsed time: 949.46s]\n",
      "[Epoch 100/200] [D loss: 0.091673] [G loss: 3.312147] [Elapsed time: 958.38s]\n",
      "[Epoch 101/200] [D loss: 0.187930] [G loss: 2.419130] [Elapsed time: 967.90s]\n",
      "[Epoch 102/200] [D loss: 0.147249] [G loss: 4.321087] [Elapsed time: 977.03s]\n",
      "[Epoch 103/200] [D loss: 0.168211] [G loss: 3.093445] [Elapsed time: 985.61s]\n",
      "[Epoch 104/200] [D loss: 0.150581] [G loss: 3.448054] [Elapsed time: 995.18s]\n",
      "[Epoch 105/200] [D loss: 0.211023] [G loss: 2.439237] [Elapsed time: 1004.64s]\n",
      "[Epoch 106/200] [D loss: 0.155590] [G loss: 4.644272] [Elapsed time: 1013.65s]\n",
      "[Epoch 107/200] [D loss: 0.053507] [G loss: 3.870691] [Elapsed time: 1022.80s]\n",
      "[Epoch 108/200] [D loss: 0.046545] [G loss: 3.698122] [Elapsed time: 1031.42s]\n",
      "[Epoch 109/200] [D loss: 0.323572] [G loss: 7.818755] [Elapsed time: 1042.61s]\n",
      "[Epoch 110/200] [D loss: 0.074050] [G loss: 4.057583] [Elapsed time: 1052.13s]\n",
      "[Epoch 111/200] [D loss: 0.144696] [G loss: 4.509466] [Elapsed time: 1061.89s]\n",
      "[Epoch 112/200] [D loss: 0.076199] [G loss: 3.496010] [Elapsed time: 1071.29s]\n",
      "[Epoch 113/200] [D loss: 0.051518] [G loss: 3.674412] [Elapsed time: 1081.00s]\n",
      "[Epoch 114/200] [D loss: 0.080849] [G loss: 3.153706] [Elapsed time: 1089.60s]\n",
      "[Epoch 115/200] [D loss: 0.111580] [G loss: 3.901149] [Elapsed time: 1098.90s]\n",
      "[Epoch 116/200] [D loss: 0.039285] [G loss: 4.294240] [Elapsed time: 1109.10s]\n",
      "[Epoch 117/200] [D loss: 0.054827] [G loss: 2.855100] [Elapsed time: 1121.52s]\n",
      "[Epoch 118/200] [D loss: 0.114420] [G loss: 4.822638] [Elapsed time: 1133.42s]\n",
      "[Epoch 119/200] [D loss: 0.105281] [G loss: 2.824579] [Elapsed time: 1144.35s]\n",
      "[Epoch 120/200] [D loss: 0.027257] [G loss: 4.362313] [Elapsed time: 1153.26s]\n",
      "[Epoch 121/200] [D loss: 0.077757] [G loss: 2.704547] [Elapsed time: 1162.71s]\n",
      "[Epoch 122/200] [D loss: 0.061467] [G loss: 3.708770] [Elapsed time: 1172.21s]\n",
      "[Epoch 123/200] [D loss: 0.062588] [G loss: 3.118497] [Elapsed time: 1182.56s]\n",
      "[Epoch 124/200] [D loss: 0.081958] [G loss: 3.534899] [Elapsed time: 1192.08s]\n",
      "[Epoch 125/200] [D loss: 0.182262] [G loss: 8.518404] [Elapsed time: 1201.54s]\n",
      "[Epoch 126/200] [D loss: 0.070770] [G loss: 5.227143] [Elapsed time: 1212.76s]\n",
      "[Epoch 127/200] [D loss: 0.096584] [G loss: 3.165926] [Elapsed time: 1226.82s]\n",
      "[Epoch 128/200] [D loss: 0.144815] [G loss: 4.118789] [Elapsed time: 1242.37s]\n",
      "[Epoch 129/200] [D loss: 0.091844] [G loss: 2.959676] [Elapsed time: 1252.83s]\n",
      "[Epoch 130/200] [D loss: 0.090679] [G loss: 3.984186] [Elapsed time: 1263.46s]\n",
      "[Epoch 131/200] [D loss: 0.090356] [G loss: 4.091345] [Elapsed time: 1274.60s]\n",
      "[Epoch 132/200] [D loss: 0.254489] [G loss: 2.794509] [Elapsed time: 1286.56s]\n",
      "[Epoch 133/200] [D loss: 0.125635] [G loss: 3.364021] [Elapsed time: 1296.37s]\n",
      "[Epoch 134/200] [D loss: 0.103334] [G loss: 5.858585] [Elapsed time: 1306.01s]\n",
      "[Epoch 135/200] [D loss: 0.148297] [G loss: 4.731649] [Elapsed time: 1314.96s]\n",
      "[Epoch 136/200] [D loss: 0.193846] [G loss: 4.964377] [Elapsed time: 1324.12s]\n",
      "[Epoch 137/200] [D loss: 0.093111] [G loss: 3.797748] [Elapsed time: 1334.08s]\n",
      "[Epoch 138/200] [D loss: 0.088610] [G loss: 4.244864] [Elapsed time: 1343.25s]\n",
      "[Epoch 139/200] [D loss: 0.132260] [G loss: 3.820100] [Elapsed time: 1351.73s]\n",
      "[Epoch 140/200] [D loss: 0.103788] [G loss: 5.939390] [Elapsed time: 1360.55s]\n",
      "[Epoch 141/200] [D loss: 0.121748] [G loss: 2.500736] [Elapsed time: 1370.19s]\n",
      "[Epoch 142/200] [D loss: 0.179935] [G loss: 2.701052] [Elapsed time: 1378.77s]\n",
      "[Epoch 143/200] [D loss: 0.094493] [G loss: 3.505563] [Elapsed time: 1387.52s]\n",
      "[Epoch 144/200] [D loss: 0.155805] [G loss: 2.406779] [Elapsed time: 1396.19s]\n",
      "[Epoch 145/200] [D loss: 0.061608] [G loss: 5.158247] [Elapsed time: 1404.15s]\n",
      "[Epoch 146/200] [D loss: 0.042601] [G loss: 3.159138] [Elapsed time: 1412.45s]\n",
      "[Epoch 147/200] [D loss: 0.242690] [G loss: 2.640232] [Elapsed time: 1423.51s]\n",
      "[Epoch 148/200] [D loss: 0.198352] [G loss: 6.428487] [Elapsed time: 1433.86s]\n",
      "[Epoch 149/200] [D loss: 0.086249] [G loss: 3.677172] [Elapsed time: 1444.60s]\n",
      "[Epoch 150/200] [D loss: 0.101694] [G loss: 2.003283] [Elapsed time: 1455.67s]\n",
      "[Epoch 151/200] [D loss: 0.134995] [G loss: 4.989804] [Elapsed time: 1465.26s]\n",
      "[Epoch 152/200] [D loss: 0.142962] [G loss: 4.030977] [Elapsed time: 1475.59s]\n",
      "[Epoch 153/200] [D loss: 0.105367] [G loss: 3.299594] [Elapsed time: 1485.41s]\n",
      "[Epoch 154/200] [D loss: 0.136829] [G loss: 3.569738] [Elapsed time: 1496.82s]\n",
      "[Epoch 155/200] [D loss: 0.178901] [G loss: 3.211874] [Elapsed time: 1506.39s]\n",
      "[Epoch 156/200] [D loss: 0.216698] [G loss: 4.417673] [Elapsed time: 1517.05s]\n",
      "[Epoch 157/200] [D loss: 0.047516] [G loss: 3.236615] [Elapsed time: 1526.73s]\n",
      "[Epoch 158/200] [D loss: 0.131425] [G loss: 2.288921] [Elapsed time: 1536.24s]\n",
      "[Epoch 159/200] [D loss: 0.050381] [G loss: 3.780112] [Elapsed time: 1545.84s]\n",
      "[Epoch 160/200] [D loss: 0.107108] [G loss: 3.976890] [Elapsed time: 1555.28s]\n",
      "[Epoch 161/200] [D loss: 0.057823] [G loss: 4.995195] [Elapsed time: 1565.21s]\n",
      "[Epoch 162/200] [D loss: 0.111708] [G loss: 3.401171] [Elapsed time: 1575.46s]\n",
      "[Epoch 163/200] [D loss: 0.063628] [G loss: 7.156208] [Elapsed time: 1585.80s]\n",
      "[Epoch 164/200] [D loss: 0.144245] [G loss: 4.789563] [Elapsed time: 1596.30s]\n",
      "[Epoch 165/200] [D loss: 0.090072] [G loss: 2.594441] [Elapsed time: 1609.51s]\n",
      "[Epoch 166/200] [D loss: 0.077045] [G loss: 3.353603] [Elapsed time: 1622.39s]\n",
      "[Epoch 167/200] [D loss: 0.099951] [G loss: 4.525778] [Elapsed time: 1634.44s]\n",
      "[Epoch 168/200] [D loss: 0.239708] [G loss: 6.312233] [Elapsed time: 1644.99s]\n",
      "[Epoch 169/200] [D loss: 0.089633] [G loss: 4.007466] [Elapsed time: 1655.64s]\n",
      "[Epoch 170/200] [D loss: 0.116733] [G loss: 2.838656] [Elapsed time: 1667.30s]\n",
      "[Epoch 171/200] [D loss: 0.106180] [G loss: 3.337934] [Elapsed time: 1678.75s]\n",
      "[Epoch 172/200] [D loss: 0.092500] [G loss: 4.497094] [Elapsed time: 1690.88s]\n",
      "[Epoch 173/200] [D loss: 0.138475] [G loss: 4.571473] [Elapsed time: 1703.13s]\n",
      "[Epoch 174/200] [D loss: 0.115692] [G loss: 3.024588] [Elapsed time: 1712.71s]\n",
      "[Epoch 175/200] [D loss: 0.122331] [G loss: 5.867408] [Elapsed time: 1723.22s]\n",
      "[Epoch 176/200] [D loss: 0.080491] [G loss: 3.041042] [Elapsed time: 1733.80s]\n",
      "[Epoch 177/200] [D loss: 0.153723] [G loss: 3.513353] [Elapsed time: 1745.21s]\n",
      "[Epoch 178/200] [D loss: 0.105239] [G loss: 2.493955] [Elapsed time: 1755.32s]\n",
      "[Epoch 179/200] [D loss: 0.089172] [G loss: 4.484561] [Elapsed time: 1765.18s]\n",
      "[Epoch 180/200] [D loss: 0.142381] [G loss: 3.923988] [Elapsed time: 1780.16s]\n",
      "[Epoch 181/200] [D loss: 0.176013] [G loss: 2.723633] [Elapsed time: 1795.37s]\n",
      "[Epoch 182/200] [D loss: 0.251839] [G loss: 2.488090] [Elapsed time: 1808.84s]\n",
      "[Epoch 183/200] [D loss: 0.084729] [G loss: 4.052144] [Elapsed time: 1825.11s]\n",
      "[Epoch 184/200] [D loss: 0.123755] [G loss: 2.327277] [Elapsed time: 1842.26s]\n",
      "[Epoch 185/200] [D loss: 0.150077] [G loss: 2.183268] [Elapsed time: 1856.67s]\n",
      "[Epoch 186/200] [D loss: 0.137317] [G loss: 6.796675] [Elapsed time: 1866.82s]\n",
      "[Epoch 187/200] [D loss: 0.095319] [G loss: 4.862632] [Elapsed time: 1876.81s]\n",
      "[Epoch 188/200] [D loss: 0.097926] [G loss: 2.447875] [Elapsed time: 1886.40s]\n",
      "[Epoch 189/200] [D loss: 0.141458] [G loss: 3.548631] [Elapsed time: 1896.27s]\n",
      "[Epoch 190/200] [D loss: 0.064915] [G loss: 3.898455] [Elapsed time: 1904.74s]\n",
      "[Epoch 191/200] [D loss: 0.086673] [G loss: 3.492689] [Elapsed time: 1913.55s]\n",
      "[Epoch 192/200] [D loss: 0.510413] [G loss: 7.037796] [Elapsed time: 1923.58s]\n",
      "[Epoch 193/200] [D loss: 0.083033] [G loss: 3.521578] [Elapsed time: 1932.63s]\n",
      "[Epoch 194/200] [D loss: 0.133055] [G loss: 4.251246] [Elapsed time: 1942.56s]\n",
      "[Epoch 195/200] [D loss: 0.125126] [G loss: 5.225632] [Elapsed time: 1953.03s]\n",
      "[Epoch 196/200] [D loss: 0.114957] [G loss: 3.791329] [Elapsed time: 1961.35s]\n",
      "[Epoch 197/200] [D loss: 0.142607] [G loss: 4.532178] [Elapsed time: 1970.09s]\n",
      "[Epoch 198/200] [D loss: 0.118118] [G loss: 9.201175] [Elapsed time: 1979.77s]\n",
      "[Epoch 199/200] [D loss: 0.111317] [G loss: 3.337937] [Elapsed time: 1988.67s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 200 # 학습의 횟수(epoch) 설정\n",
    "sample_interval = 5000 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 랜덤 노이즈(noise) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).to(device)\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = generator(z)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n",
    "            save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"Result_img/90000.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('GAN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27188a68af24359f716f42331a05ac5c5dd63b6f781f49d2f8f4a4081f86e482"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
